\textbf{2.1 Solution.} Suppose we have $v_1,v_2\in V$. Then $(v_1+U)+(v_2+U) = (v_1+v_2)+U$. Now, suppose we have a $v_1'\in V$ such that $v_1+U = v_1'+U$. It follows that $v_1'-v_1\in U$ by Exercise \textbf{1.20}. Therefore we have
\begin{align*}
    (v_1'+U)+(v_2+U) &= (v_1'+v_2+U) \\
                     &= (v_1+v_2)+(v_1'-v_1)+U \\
                     &= (v_1+v_2)+U \\
                     &= (v_1+U)+(v_2+U).
\end{align*}
Notice that the $(v_1'-v_1)$ gets absorbed into $U$ since it is an element of $U$. We can do the same thing for a $v_2'$ such that $v_2'+U=v_2+U$, but the proof is the same due vector space commutativity. Thus, the rule for addition in $V/U$ is well-defined.

\textbf{2.2 Solution.} Since $V/U$ is a vector space endowed with the provided rules of addition and scalar multiplication, we only need to show that $|W|/|U|\subseteq|V|/|U|$, $|W|/|U|$ is nonempty, and that it is closed under addition and scalar multiplication.

Since $|W|/|U|$ is the set $\{w+U\mid w\in W\}$ and $|V|/|U|$ is the set $\{v+U\mid v\in V\}$, it follows that $|W|/|U|\subseteq|V|/|U|$ since $W\sqsubseteq V$ and therefore $|W|\subseteq|V|$.

Next, we know that $|W|/|U|$ must be nonempty since $|W|$ and $|U|$ are nonempty ($|W|$ and $|U|$ are both nonempty since $U\sqsubseteq W\sqsubseteq V$, so both must contain the $0$ vector).

Finally, we show that $W/U$ is closed under addition and scalar multiplication. Since $W$ is a vector space, for any $w_1,w_2\in W$, we know that $w_1+w_2\in W$. Therefore for any $w_1+U,w_2+U\in W/U$, we know that $w_1+w_2+U\in W/U$. Furthermore, for any $w\in W$ and $a\in\mathbb{F}$, we know that $aw\in W$. Therefore for any $w+U\in W/U$, we know that $aw+U\in W/U$. It follows that $W/U$ is closed under both operations.

Thus $W/U\sqsubseteq V/U$.

\textbf{2.3 Solution.} We can see that $\mathbb{R}^3/E_3$ is the space whose underlying set is $\{(x,y,z)+E_3\mid x,y,z\in\mathbb{R}\}$. In other words, it is the collection of all lines parallel to the $z$-axis. Denote the line parallel to the $z$-axis passing through points $(x,y,z)\mid z\in\mathbb{R}$ as $[x,y]$. It follows that there is a 1-to-1 correspondence between $[x,y]\in\mathbb{R}^3/E_3$ and ordered pairs $(x,y)\in\mathbb{R}^2$ given by the isomorphic mapping $\phi:[x,y]\mapsto(x,y)$.

Now we will show that $\phi$ is well-defined. We know there exists a bijection between lines parallel to the $z$-axis in $\mathbb{R}^3/E_3$ and ordered pairs $(x,y)$ in $\mathbb{R}^2$. Now, if we define $[x_1,y_1]+[x_2,y_2] = [x_1+x_2,y_1+y_2]$, then it follows that $\phi([x_1,y_1]+[x_2,y_2]) = \phi([x_1+x_2,y_1+y_2]) = (x_1+x_2,y_1+y_2) = (x_1,y_1)+(x_2,y_2) = \phi([x_1,y_1])+\phi([x_2,y_2])$, so $\phi$ satisfies additivity. Furthermore, if we define $a[x,y] = [ax,ay]$, then it follows that $\phi(a[x,y]) = \phi([ax,ay]) = (ax,ay) = a(x,y) = a\phi([x,y])$, so $\phi$ satisfies homogeneity. Therefore $\phi$ is a bijective homomorphism, and thus a well-defined isomorphism.

\textbf{2.4 Solution.} For any $v_1,v_2\in V$, we have that 
\begin{align*}
    \pi_U(v_1+v_2) &= (v_1+v_2) + U \\
                   &= (v_1+U) + (v_2+U) \\
                   &= \pi_U(v_1) + \pi_U(v_2),
\end{align*}
so $\pi_U$ satisfies additivity.

Furthermore, for any $v\in V$ and $a\in\mathbb{F}$, we have that
\begin{align*}
    \pi_U(av) &= av + U \\
              &= (v+U) + \ldots + (v+U) \text{(where (v+U) appears a times)} \\
              &= a(v+U) \\
              &= a\pi_U(v),
\end{align*}
so $\pi_U$ satisfies homogeneity.

Thus $\pi_U$ is linear.

\textbf{2.5 Solution.} (a) For every coset $[v]\in V/U$, the element $v\in V$ is mapped to $[v]$, i.e. $\pi_U(v)=v+U=[v]$. Therefore $\pi_U$ is surjective. 

For all $u\in|U|$, we have that $\pi_U(u)=u+U=|U|$, since $u\in|U|$ implies $u-0\in|U|$, and therefore $u+U=0+U$, which means that the underlying set of $u+U$ is equivalent to the underlying set of $0+U$, which is just $|U|$.

(b) For every $e\in E$, we have that $\pi_U(e) = e+U$. Then, we have that $\pi_U^{-1}(e+U)$ is the set $\{e+u\mid u\in|U|\}$ for every $e\in E$ (since $\pi_U(\{e+u\mid u\in|U|\}) = \{e+u+U\mid e\in E,u\in U\} = \{e+U\mid e\in E\} = e+U$), which is the same thing as the set $\{e+u\mid e\in E, u\in |U|\}$. It follows that $\pi_U^{-1}(\pi_U(E)) = E+|U|$.

(c) For $E+|U|\sqsubseteq V$, we must have either $E\sqsubseteq V$ or $E\subseteq |U|$. If $E\sqsubseteq V$, then $E+|U|$ is the vector space generated by the union of the generating vectors in $E$ and $|U|$, which must be a subspace of $V$ since both $E$ and $U$ are subspaces of $V$. If $E\subseteq |U|$, then $E+|U|$ is just $U$, which is a subspace of $V$.

\textbf{2.6 Solution.} The quotient space of $V/V$ is just $V$ itself. That is, the underlying set of $V/V$ is $\{v+V\mid v\in V\}$, which is just $|V|$ since for every $v\in V$, $v$ gets absorbed into $V$.

For every $v_1,v_2\in V$, we have that $[v_1]+[v_2]=v_1+v_2+V=|V|$ since $v_1+v_2\in V$. Similarly, for every $v\in V$ and $a\in\mathbb{F}$, we have $a[v]=av+V=|V|$ since $av\in V$.

\textbf{2.7 Solution.} The quotient space $V/U$ consists of the set of all $\{v+U\mid v\in V\}$. Suppose we have some $v\in V$. Then for every $v_i$ for $1\leq i\leq s$, $[v]+[v_i] = (v+U)+(v_i+U) = v+v_i+U = v + U = [v]$ since $v_i\in U$ (it must be, as it's a generator for $U$). Thus the $[v_i]$ are the zero elements of $V/U$.

\textbf{2.8 Solution.} Exercise \textbf{1.30} is essentially the same if we let $T$ be the quotient map $\pi_U:V\to V/U$. That is, we have the equation $\pi_U(v) = [v_0]$ for some given $v_0$. Then solutions to this equation are all of the form $v=v_0+u$ for $u\in U$. It follows that $u\in ker(\pi_U)$ since $\pi_U(u) = u+U = |U|$, which is the zero element of $V/U$. We can check the solutions by plugging in $v$, i.e. $\pi_U(v_0+u) = \pi_U(v_0)+\pi_U(u) = [v_0] + 0 = [v_0]$.

\textbf{2.9 Solution.} Say our bijective function is $f:Hom(V,W)\to Hom(V/U,W)$ with $T\mapsto\widetilde{T}$ for $T\in Hom(V,W)$ and $\widetilde{T}\in Hom(V/U,W)$. We have shown previously that $Hom(V,W)$ is a subspace (and therefore a vector space) of $\mathcal{F}(V,W)$ for vector spaces $V$ and $W$. Then since $V/U$ is a vector space, $Hom(V/U,W)$ is also a vector space.

To show additivity, let $T_1,T_2\in Hom(V,W)$ and $\widetilde{T_1},\widetilde{T_2}\in Hom(V/U,W)$ such that $f(T_1)=\widetilde{T_1}$ and $f(T_2)=\widetilde{T_2}$. It follows that $T_1+T_2\in Hom(V,W)$ and $\widetilde{T_1}+\widetilde{T_2}\in Hom(V/U,W)$. Define $\widetilde{T_1+T_2} = \widetilde{T_1}+\widetilde{T_2}$. Then for every $v\in V$ we have
\begin{align*}
    f(T_1+T_2)(v) &= \widetilde{(T_1+T_2)}(v) \\
                  &= \widetilde{T_1}(v)+\widetilde{T_2}(v) \\
                  &= f(T_1)(v)+f(T_2)(v)
\end{align*}
by vector space properties of $Hom(V,W)$ and $Hom(V/U,W)$, therefore satisfying additivity.

To show homogeneity, let $T\in Hom(V,W)$ and $\widetilde{T}\in Hom(V/U,W)$ with $f(T)=\widetilde{T}$. Also let $a\in\mathbb{F}$. It follows that $aT\in Hom(V,W)$ and $\widetilde{aT}\in Hom(V/U,W)$. Define $\widetilde{aT} = a\widetilde{T}$. Then for every $v\in V$, we have
\begin{align*}
    f(aT)(v) &= \widetilde{aT}(v) \\
             &= a\widetilde{T}(v) \\
             &= af(T)(v)
\end{align*}
by vector space properties of $Hom(V,W)$ and $Hom(V/U,W)$, therefore satisfying homogeneity.

Thus the bijection $T\mapsto\widetilde{T}$ is indeed a homomorphism.

\textbf{2.10 Solution.} By the pushforward corollary, $T\circ\pi_U = \pi_{S(U)}\circ S$. Then, for any $v,v'\in V$ suppose $v'-v\in U$. Then $\pi_U(v') = v+U$. We then get
\begin{align*}
    T(v+U) &= \pi_{S(U)}(S(v')) \\
           &= \pi_{S(U)}(S(v'+v-v)) \\
           &= S(v'+v-v)+S(U) \\
           &= S(v)+S(v'-v)+S(U) \\
           &= S(v)+S(v'-v+U) \\
           &= S(v)+S(U)
\end{align*}
by linearity of $S$. Thus $T$ sends $v+U$ to the coset $S(v)+S(U)$.

\textbf{2.11 Solution.} For the first part, the RHS is the space whose underlying set is $\{v+U\mid T(v)=0, v\in V\}$. The LHS is the space whose underlying set is $\{[v]\mid \widetilde{T}([v])=0, [v]\in V/U\}$. In Theorem \textbf{2.1.6} we defined $\widetilde{T}([v])=T(v)$ for every $[v]\in V/U$. Then we can rewrite the underlying set of the LHS as $\{v+U\mid \widetilde{T}([v])=T(v)=0\}$, which is just the underlying set of the RHS. Therefore $ker(\widetilde{T}) = ker(T)/U$.

Similarly, for the second part, the RHS is the space whose underlying set is $\{T(v)\mid v\in V\}$. The LHS is the space whose underlying set is $\{\widetilde{T}([v])\mid [v]\in V/U\}$. Since $\widetilde{T}([v])=T(v)$ for every $[v]\in V/U$, we can rewrite the set of the LHS as $\{\widetilde{T}([v])\mid v\in V\}$, which is just the underlying set of the RHS. Therefore $ran(\widetilde{T})=ran(T)$.

\textbf{2.12 Solution.} Let $X$ be the set of all sets. Then the relation on $X$ of sets having the same cardinality satisfies (we will write $|S|$ to denote the cardinality of a set $S$):
\begin{itemize}
    \item (reflexivity) For every set $S\in X$, $S\sim S$ since $|S|=|S|$.
    \item (symmetry) For all sets $S_1,S_2\in X$, if $S_1\sim S_2$, then $|S_1|=|S_2|$, so it must be true that $|S_2|=|S_1|$, which implies $S_2\sim S_1$.
    \item (transitivity) For all sets $S_1,S_2,S_3\in X$, if $S_1\sim S_2$ and $S_2\sim S_3$, then $|S_1|=|S_2|=|S_3|$ and thus $S_2\sim S_3$.
\end{itemize}

\textbf{2.13 Solution.} We shall denote $X$ as the set $\mathbb{Z}\times\mathbb{Z}\setminus\{0\}$.

(a) For every $(a,b)\in X$, $(a,b)\sim(a,b)$ since $ab=ab$, satisfying reflexivity. For all $(a,b),(c,d)\in X$, if $(a,b)\sim(c,d)$ then $ad=cb$, or $cb=ad$, which implies $(c,d)\sim(a,b)$, satisfying symmetry. For all $(a,b),(c,d),(e,f)\in X$, if $(a,b)\sim(c,d)$ and $(c,d)\sim(e,f)$ then $ad=cb$ and $cf=ed$. Multiplying the first equation by $f$ and the second by $b$, we get $adf=cbf$ and $cbf=edb$, so $adf=edb$. Multiplying by the multiplicative inverse of $d$ we get $af=eb$, which implies $(a,b)\sim(e,f)$, satisfying transitivity. Thus so $\sim$ is an equivalence relation.

(b) First we show that addition is well-defined. Suppose we have $(a,b),(c,d),(a',b')\in X$ such that $(a,b)\sim(a',b')$. Then $ab'=a'b$. We evaluate $[(a,b)]+[(c,d)]=[(ad+cb,bd)]$ and $[(a',b')]+[(c,d)]=[(a'd+cb',b'd)]$. Then, since
\begin{align*}
    (ad+bc)(b'd) &= adb'd+bcb'd \\
                 &= a'dbd+b'cbd \\
                 &= (a'd+b'c)(bd),
\end{align*}
we deduce that $[(ad+cb,bd)]\sim[(a'd+cb',b'd)]$. Therefore addition is well-defined.

Now we show that multiplication is well-defined. Suppose we have the same $(a,b),(c,d),(a',b') \in X$ from before. Then we evaluate $[(a,b)]\cdot[(c,d)] = [(ac,bd)]$ and $[(a',b')]\cdot[(c,d)] = [(a'c,b'd)]$. Then, since 
\begin{align*}
    (ac)(b'd) &= acb'd \\
              &= a'cbd \\
              &= (a'c)(bd),
\end{align*}
we deduce that $[(ac,bd)]\sim[(a'c,b'd)]$. Therefore multiplication is also well-defined.

(c) First we show that $(X,+)$ is abelian. The additive identity is the equivalence class $[(0,1)]$. For every equivalence class $[(a,b)]$, the additive inverse is $[(-a,b)]$. For all equivalence classes $[(a,b)],[(c,d)],[(e,f)]$, we have $[(a,b)]+([(c,d)]+[(e,f)])=[(adf+bcf+bed,bdf)]=([(a,b)]+[(c,d)])+[(e,f)]$, satisfying associativity. Furthermore, we have $[(a,b)]+[(c,d)]=[(ad+cb,bd)]=[(cb+ad,db)]=[(c,d)]+[(a,b)]$, satisfying commutativity. Therefore $(X,+)$ is an abelian group.

Now, we show that $(X\setminus\{0\},\cdot)$ is abelian. The multiplicative identity is the class $[(a,a)]$. For every equivalence class $[(a,b)]$, the multiplicative identity is $[(b,a)]$. For all equivalence classes $[(a,b)],[(c,d)],[(e,f)]$, we have $[(a,b)]\cdot([(c,d)]\cdot[(e,f)]) = [(ace,bdf)] = ([(a,b)]\cdot[(c,d)])\cdot[(e,f)]$, satisfying associativity. Furthermore, we have $[(a,b)]\cdot[(c,d)] = [(ac,bd)] = [(ca,db)] = [(c,d)]\cdot[(a,b)]$, satisfying commutativity. Therefore $(X\setminus\{0\},\cdot)$ is an abelian group.

Finally, we verify distributivity. For all equivalence classes $[(a,b)],[(c,d)],[(e,f)]$, we have that $[(a,b)]\cdot([(c,d)]+[(e,f)]) = [(a,b)]\cdot[(cf+ed,df)] = [(acf+aed, bdf)] = [(b,b)]\cdot[(acf+aed, bdf)] = [(acfb+aedf,bdfb)] = [(a,b)]\cdot[(c,d)]+[(a,b)]\cdot[(e,f)]$.

Thus the set $X$ with the given operations is a field.

\textbf{2.14 Solution.} For every $a\in X$, $a$ must be in the same element of $P$ as itself, satisfying reflexivity. For every $a,b\in X$, if $a$ and $b$ are in the same element of $P$ then it follows that $b$ and $a$ are in the same element of $P$, satisfying symmetry. For every $a,b,c\in X$, if $a$ and $b$ are in the same element of $P$ and $b$ and $c$ are in the same element of $P$, then it follows that $a$ and $c$ are also in the same element of $P$, satisfying transitivity.

Conversely, if we have an equivalence relation $\sim$ on $X$, then the properties of reflexivity, symmetry, and transitivity guarantee that any element of $X$ must be in a single disjoint subset of $X$ (if, we assume for sake of contradiction that $\exists$ and element that is in more than one disjoint subset, then we can merge those disjoint subsets into one single disjoint subset, and reflexivity, symmetry, and transitivity will still hold).

\textbf{2.15 Solution.} Denote the value of $a_n/b_m$ for a $r\in\mathcal{R}$ as $f_r$ (Note that $f_r$ is a real number). Suppose we have real rational functions $r,s,t\in\mathcal{R}$ such that $r\prec s$. It follows that $0\prec s-r$, so $0 < f_s-f_r=f_s-f_r+f_t-f_t=(f_s+f_t)-(f_r+f_t)$. Then $f_r+f_t < f_s+f_t$, which implies that $r+t\prec s+t$. Similarly, suppose we have real rational functions $r,s\in\mathcal{R}$ such that $0\prec r$ and $0\prec s$. Then we have $0 < f_r$ and $0 < f_s$. Since $\mathbb{R}$ is an ordered field, we know that $0 < f_rf_s$. It follows that $0\prec rs$. Thus $(\mathcal{R},\prec,+,\times)$ is an ordered field.

Let $r(x)=p(x)-q(x)=x-c$. Then $r(x)=\frac{x-c}{1}$, so $f_r=\frac{1}{1}=1>0$. It follows that $0\prec r=p-q$, and therefore $q\prec p$, so the identity polynomial is greater than any constant polynomial using this order.

\textbf{2.16 Solution.} For all endomorphisms $T:\mathcal{R}\to\mathcal{R}$, there exists a unique $p\in\mathcal{R}$ such that $T(r)=p\cdot r$ for all $r\in\mathcal{R}$ (In a way, we are likening the vector space $\mathcal{R}$ over the field $\mathcal{R}$ to the one-dimensional vector space $\mathbb{R}$ over the field $\mathcal{R}$).

\textbf{2.17 Solution.} For every $x\in\mathbb{R}$, $x\sim x$ since $x=x+2\pi(0)$, satisfying reflexivity. For every $x,y\in\mathbb{R}$, if $x\sim y$, then there is an integer $n$ s.t. $y=x+2\pi n$. It follows that $x=y+2\pi(-n)$, and so $y\sim x$, satisfying symmetry. Finally, for every $x,y,z\in\mathbb{R}$, if we have $x\sim y$ and $y\sim z$, then $y=x+2\pi(n)$ and $z=y+2\pi(m)$ for integers $n$ and $m$. It follows that $z=x+2\pi(n+m)$, so $x\sim z$, satisfying transitivity. Thus $\sim$ is an equivalence relation.

Define a function $f:\mathbb{R}/\sim\to[0,2\pi)$ with $f([x])=x$ for $x\in[0,2\pi)$ (note that $[0,2\pi)$ covers the set $\mathbb{R}/\sim$). Then for every $x\in[0,2\pi)$, there exists a $[x]\in\mathbb{R}/\sim$ such that $f([x])=x$, so $f$ is surjective. Furthermore, if we have $x,x'\in[0,2\pi)$ such that $f([x])=f([x'])$. It follows then that $x=f([x])=f([x'])=x'$, so $f$ is injective. Therefore $f$ is bijective.

The mapping $(x,y)\mapsto\theta$ for $(x,y)\in S^1$ and $\theta\in[0,2\pi)$ is a bijection since every point $p$ on the unit circle with origin $o$ is in one-to-one correspondence to the angle $\overline{op}$ makes with the $x$-axis. Then, since there is a bijection between $\mathbb{R}/\sim$ and $[0,2\pi)$, it follows that there is a bijection between $\mathbb{R}/\sim$ and $S^1$.

Proof by counterexample: Let $x=0\in[0,2\pi)$. Then $[0]$ is the same equivalence class as $[2\pi]$. We have $f([0])=0^2=0$ and $f([2\pi])=(2\pi)^2=(2\pi)(2\pi)$. But since $2\pi$ is not an integer, $0\not\sim (2\pi)(2\pi)$, and $f([0])\neq f([2\pi])$. Thus $f([x])=x^2$ is not well-defined.

\textbf{2.18 Solution.} From the universal property of quotient maps \textbf{2.1.6}, we know that $ker(\widetilde{\pi}_W) = ker(\pi_W)/U$ since $U\sqsubseteq V$. Also, since $\pi_W(w) = w+W = W$ for all $w\in W$, $ker(\pi_W) = W$. So we have so far $ker(\widetilde{\pi}_W) = ker(\pi_W)/U = W/U$.

The set $\{w+U\mid w\in W\}$ corresponds to $W/U$ and the set $\{v+U\mid v\in V\}$ corresponds to $V/U$. It follows that $W/U\sqsubseteq V/U$ since $W\sqsubseteq V$ (therefore $|W|\subseteq|V|$) and since $W/U$ is closed under addition and s.m. (if $[w],[w']\in W/U$, then $[w]+[w']=[w+w']\in W/U$, and if $a\in\mathbb{F}$, then $a[w]=[aw]\in W/U$).

Thus we have $ker(\widetilde{\pi}_W) = ker(\pi_W)/U = W/U \sqsubseteq V/U$.

\textbf{2.19 Solution.} By the first isomorphism theorem, $V/ker(T)$ is isomorphic to $ran(T)$, which in this case is just $W$, so $V/ker(T)\cong W$. By the correspondence theorem, since $ker(T)\sqsubseteq V$, the quotient map becomes $\pi:V\to V/ker(T)\cong W$, so $T=\pi$. Then since $U'\to\pi(U')$ is a bijection between subspaces of $V$ containing $ker(T)$ and subspaces of $V/ker(T)\cong W$, we have that the map $U\to T^{-1}(U)$ is a bijection between subspaces of $W$ and subspaces of $V$ containing $ker(T)$.

\textbf{2.20 Solution.} By the correspondence theorem, if we take $W_1 = V/U$ and $W_2 = Z$ for all subspaces $Z\sqsubseteq V/U$, then we have that $W_2\sqsubseteq W_1$ which implies $W_2/W_1 \cong \frac{W_2/U}{W_1/U}$, or $\frac{V/U}{Z} \cong \frac{\frac{V/U}{U}}{Z/U}$. Since $\frac{V/U}{U} = \frac{V/U}{U/U} \cong V/U$, we have $\frac{V/U}{Z} \cong \frac{V/U}{Z/U} \cong \frac{V}{Z}$ by the third isomorphism theorem. Thus every quotient space of $V/U$ is isomorphic to a quotient space of $V$.

\textbf{2.21 Solution.} To show additivity, suppose we have $(u,v),(u',v')\in V\oplus V$. Then we have
\begin{align*}
    T((u,v)+(u',v')) &= T((u+u',v+v')) \\
                    &= ((u+u')cos\theta + (v+v')sin\theta, -(u+u')sin\theta + (v+v')cos\theta) \\
                    &= (ucos\theta + vsin\theta, -usin\theta + vcos\theta) + (u'cos\theta + v'sin\theta, -u'sin\theta + v'cos\theta) \\
                    &= T(u,v) + T(u',v').
\end{align*}

Now we check homogeneity. Suppose we have $(u,v)\in V\oplus V$ and $a\in\mathbb{R}$. Then we have
\begin{align*}
    T(a(u,v)) &= T(au,av) \\
              &= (aucos\theta + avsin\theta, -ausin\theta + avcos\theta) \\
              &= a(ucos\theta + vsin\theta, -usin\theta + vcos\theta) \\
              &= aT(u,v).
\end{align*}

Thus $T$ is linear.
\section{Homework 7}

\subsection{Reducible Markov Chain}
(a) The communicating classes are $\{0, 1\}$ (recurrent), $\{2, 3\}$ (transient), and $\{4, 5\}$ (recurrent).

(b) Taking into consideration the communicating classes, let $\rho(i)$ be the probability that we reach state 0 before 5 if starting from state $i$. Evidently, we only need to worry about states 2 and 3, so we have the balance equations
\begin{align*}
    \rho(2) &= \frac{1}{2} \cdot 1 + \frac{1}{2}\rho(3) \\
    \rho(3) &= \frac{1}{2} \cdot 0 + \frac{1}{2}\rho(2),
\end{align*}
from which we get that $\rho(2) = 2/3$.

(c) Clearly any stationary distribution cannot have a positive value for either of states 2 or 3 since they are transient. Suppose $x$ of the distribution goes to the left and $1 - x$ of the distribution goes to the right. Then since we have
\begin{align*}
    \pi_0 &= (1 - \alpha)\pi_0 + \beta\pi_1 \\
    \pi_1 &= \alpha\pi_0 + (1 - \beta)\pi_1,
\end{align*}
from which we get that $\pi_0 = \frac{\beta x}{\alpha + \beta}$ and $\pi_1 = \frac{\alpha x}{\alpha + \beta}$. Similarly $\pi_4 = \frac{q(1 - x)}{p + q}$ and $\pi_5 = \frac{p(1 - x)}{p + q}$. Summarizing, we have
\[
\pi^* = \left[\frac{\beta x}{\alpha + \beta}, \frac{\alpha x}{\alpha + \beta}, 0, 0, \frac{q(1 - x)}{p + q}, \frac{p(1 - x)}{p + q}\right]
\]
for some $x \in [0, 1]$.

(d) We track the portion of the distribution that ends up in the absorbing state to the left as the geometric series:
\begin{align*}
    \frac{1}{2}\gamma + \frac{1}{4}(1 - \gamma) + \frac{1}{8}\gamma + \frac{1}{16}(1 - \gamma) + \dots &= \gamma\sum_{i = 1}^\infty (-1)^{i + 1}\left(\frac{1}{2}\right)^i + \sum_{i = 1}^\infty\left(\frac{1}{4}\right)^i \\
    &= \frac{1}{3}\gamma + \frac{1}{3}.
\end{align*}
So setting this as $x$ from the previous part, we see that the distribution of the chain converges to
\[
\pi^* = \left[\frac{\beta(\gamma + 1)}{3\alpha + 3\beta}, \frac{\alpha(\gamma + 1)}{3\alpha + 3\beta}, 0, 0, \frac{q(2 - \gamma)}{3p + 3q}, \frac{p(2 - \gamma)}{3p + 3q}\right]
\]

\subsection{Product of Dice Rolls}
Let $\tau(i)$ be the expected hitting time given that the last roll was an $i$. Then the expected hitting time from the start is 
\[
1 + \sum_{i = 1}^6\frac{1}{6}\tau(i).
\]
For the $\tau(i)$ we have the following hitting time equations:
\begin{align*}
    \tau(1) &= 1 + \frac{1}{6}\tau(1) + \frac{1}{6}\tau(2) + \frac{1}{6}\tau(3) + \frac{1}{6}\tau(4) + \frac{1}{6}\tau(5) + \frac{1}{6}\tau(6) \\
    \tau(2) &= 1 + \frac{1}{6}\tau(1) + \frac{1}{6}\tau(2) + \frac{1}{6}\tau(3) + \frac{1}{6}\tau(4) + \frac{1}{6}\tau(5) \\
    \tau(3) &= 1 + \frac{1}{6}\tau(1) + \frac{1}{6}\tau(2) + \frac{1}{6}\tau(3) + \frac{1}{6}\tau(5) + \frac{1}{6}\tau(6) \\
    \tau(4) &= 1 + \frac{1}{6}\tau(1) + \frac{1}{6}\tau(2) + \frac{1}{6}\tau(4) + \frac{1}{6}\tau(5) + \frac{1}{6}\tau(6) \\
    \tau(5) &= 1 + \frac{1}{6}\tau(1) + \frac{1}{6}\tau(2) + \frac{1}{6}\tau(3) + \frac{1}{6}\tau(4) + \frac{1}{6}\tau(5) + \frac{1}{6}\tau(6) \\
    \tau(6) &= 1 + \frac{1}{6}\tau(1) + \frac{1}{6}\tau(3) + \frac{1}{6}\tau(4) + \frac{1}{6}\tau(5) + \frac{1}{6}\tau(6)
\end{align*}
Solving, we get $\tau(1) = \tau(5) = 21/2$ and $\tau(2) = \tau(3) = \tau(4) = \tau(6) = 9$. Thus our final answer is
\[
1 + \frac{1}{6}\left(\frac{21}{2} + 9 + 9 + 9 + \frac{21}{2} + 9\right) = \frac{21}{2}.
\]

Unsatisfied with this brute force approach, we realize that there are symmetries in the problem. In particular, we can fuse 2, 3, 4, and 6 into one state $A$ (the state that denotes the last roll being a 2, 3, 4, or 6). Similarly, we can fuse 1 and 5 into one state $B$. Denote $C$ the absorbing state where the product of the last \textit{two} dice rolls is a 12. Then we get the following hitting time equations:
\begin{align*}
    \tau(A) &= 1 + \frac{1}{2}\tau(A) + \frac{1}{3}\tau(B) \\
    \tau(B) &= 1 + \frac{2}{3}\tau(A) + \frac{1}{3}\tau(B) \\
    \tau(C) &= 0
\end{align*}
which we solve to obtain $\tau(A) = 9$ and $\tau(B) = 21/2$. Then our desired hitting time is just
\[
1 + \frac{2}{3} \cdot 9 + \frac{1}{3} \cdot \frac{21}{2} = \frac{21}{2}.
\]

\subsection{Twitch Plays Pokemon}
(a) We group squares by symmetry into the following cluster states:
\begin{align*}
    A&: (0, 0) \\
    B&: (1, 0), (0, 1) \\
    C&: (2, 0), (1, 1), (0, 2) \\
    D&: (2, 1), (1, 2) \\
    E&: (2, 2)
\end{align*}
From this we have simplified hitting time equations:
\begin{align*}
    \tau_A &= 1 + \tau_B \\
    \tau_B &= 1 + \frac{1}{3}\tau_A + \frac{2}{3}\tau_C \\
    \tau_C &= 1 + \frac{1}{2}\tau_B + \frac{1}{2}\tau_D \\
    \tau_D &= 1 + \frac{2}{3}\tau_C \\
    \tau_E &= 0
\end{align*}
which we solve to obtain $\tau_A = 18$.

(b) Using symmetry, we get the probabilities of going to the rightmost stairs first:
\begin{align*}
    p = \rho(0, 0) \\
    1/2 &&= \rho(0, 1) = \rho(1, 1) = \rho(2, 1) \\
    1 - p &= \rho(0, 2) \\
    q &= (1, 0) \\
    1 - q &= (1, 2) \\
    0 &= \rho(2, 0) \\
    1 &= \rho(2, 2)
\end{align*}
We solve these to get $p = 2/5$.


\subsection{Fly on a Graph}
(a) The model of the fly directly adheres to the definition of a Markov Chain. In particular, at time $n$, a fly at state $i$ picks one of its neighbors and with some transition probability makes the transition on to a neighboring state, only dependent on its current state and no state before that.

The stationary distribution can be found with the balance equations:
\begin{align*}
    \pi_1 &= \frac{1}{2}\pi_2 + \frac{1}{3}\pi_4 \\
    \pi_2 &= \frac{1}{2}\pi_1 + \frac{1}{2}\pi_3 \\
    \pi_3 &= \frac{1}{2}\pi_2 + \frac{1}{3}\pi_4 \\
    \pi_4 &= \frac{1}{2}\pi_1 + \frac{1}{2}\pi_3 + \pi_5 \\
    \pi_5 &= \frac{1}{3}\pi_4 \\
    \sum_{i = 1}^5\pi_i &= 1.
\end{align*}
Solving, we obtain the stationary distribution
\[
\pi^* = \left[\frac{1}{5}, \frac{1}{5}, \frac{1}{5}, \frac{3}{10}, \frac{1}{10}\right]
\]

(b) We can cluster nodes 1 and 3 together by symmetry, and we get the first-hitting time equations:
\begin{align*}
    \rho(1, 3) &= \frac{1}{2}\rho(4) \\
    \rho(4) &= \frac{2}{3}\rho(1, 3) + \frac{1}{3}.
\end{align*}
We solve to get $\rho(1) = \rho(1, 3) = 1/4$.

(c) This new process is not a Markov Chain, as it fails to satisfy the amnesia property. If the fly goes from 1 to 2, then the probability of it going from 2 to 3 is 1, and the probability of it going from 2 back to 1 is 0. However, if the fly first goes from 1 to 4 and then to 3 and then to 2, the probability of it going from 2 to 3 is 0 whereas the probability of it going from 2 to 1 is 1. In particular, the fly's transition probabilities depend on not only the current state it is at but also the state before that, whereas the markov property says it must be independent of all past events except the current one.


\subsection{Metropolis Hastings Algorithm}
(a) Since we can compute $\pi$ up to a normalizing constant, we have that the ratio $\pi(x)/\pi(y) = \tilde{\pi}(x)/\tilde{\pi}(y)$. As it is efficient to draw samples from $\tilde{\pi}$, we can efficiently compute the acceptance probability function $A(x, y)$, and so the markov chain can be computed efficiently, even though directly computing $\pi$ may not be.

(b) Since the detailed balance equations hold, we have
\begin{align*}
    \pi(x) &= \sum_y \pi(y)P(y, x) \\
        &= \sum_y \pi(x)P(x, y) \\
        &= \pi(x)\sum_y P(x, y) \\
        &= \pi(x).
\end{align*}
In particular, the distribution $\pi$ satisfies the balance equations. Since the markov chain is finite and irreducible, we know that the stationary distribution exists and is unique. Thus this $\pi$ must be the stationary distribution.

(c) Given states $x$ and $y$, suppose (WLOG) that $\pi(x)f(x, y) \leq \pi(y)f(y, x)$. Then $A(x, y) = 1$, i.e. the proposal of $y$ given $x$ is always accepted. Therefore we have
\[
\pi(x)P(x, y) = \pi(x)f(x, y).
\]
Furthermore, we have that $A(y, x) = \frac{\pi(x)f(x, y)}{\pi(y)f(y, x)}$, so that
\[
\pi(y)P(y, x) = \pi(y)f(y, x)\left(\frac{\pi(x)f(x, y)}{\pi(y)f(y, x)}\right) = \pi(x)f(x, y).
\]
It follows that 
\[
\pi(y)P(y, x) = \pi(x)P(x, y)
\]
for every pair of states $x$ and $y$. Thus the detailed balance equations hold and so $\pi$ is the stationary distribution of the chain.

(d) Since there is a 1/2 probability of the chain not moving, the chain now has self loops, and is therefore aperiodic. The stationary distribution stays the same since the detailed balance equations still hold. In particular, for every pair of distinct states $x$ and $y$, the transition probability is now multiplied by 1/2. But since the detailed balance equations are symmetric, both sides are multiplied by 1/2 and so they remain true for every pair of distinct $x, y$. If $x = y$, then the detailed balance equation holds regardless due symmetry.

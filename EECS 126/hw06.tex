\section{Homework 6}

\subsection{The Weak Law of Large Numbers}
(a) Since the $X_i$ are iid and the transform of sum of random variables is just the product of their transforms, we have
\begin{align*}
    M_{\bar{X}_n}(s) &= \prod_{i = 1}^n M_{X_i/n}(s) \\
        &= \prod_{i = 1}^n \E[e^{sX_i/n} \\
        &= \prod_{i = 1}^n M_{X_i}(s/n) \\
        &= M_{X}(s/n)^n.
\end{align*}

(b) We have
\begin{align*}
    M_X(s) &= \E[e^{sX}] \\
    &= \E\left[1 + sX + \frac{(sX)^2}{2!} + \dots\right] \\
    &= 1 + \E[X]s + \E\left[\frac{(sX)^2}{2!} + \dots\right],
\end{align*}
where the rightmost term can be seen to be the function $o(s)$, since it is a series with terms whose degrees are all at least 2, so $\lim_{s \to 0}o(s)/s = 0$. It follows that $a = 1$ and $b = \mu$.

(c) We have from the previous parts that
\begin{align*}
    \lim_{n \to \infty}M_{\bar{X}_n}(s) &= \lim_{n \to \infty}\left(1 + \frac{\mu s}{n} + o(s/n)\right)^n \\
    &= \lim_{n \to \infty}\left(1 + \frac{\mu s + no(s/n)}{n}\right)^n.
\end{align*}
Now, note that since
\[
    \lim_{n \to \infty}no(s/n) = \lim_{s \to 0}\frac{1}{s}o(s) = 0
\]
from our assumptions in the previous part, so we have that the numerator $\mu s + no(s/n)$ is a sequence that converges to $\mu s$. We then get the limit
\[
    \lim_{n \to \infty}\left(1 + \frac{\mu s + no(s/n)}{n}\right)^n = e^{\mu s}.
\]

(d) Consider the random variable $Y$ with $\P[Y = \mu] = 1$, i.e. all of its probability mass is concentrated at $\mu$. Note that $M_Y(s) = \E[e^{sY}] = e^{\mu s}$. Since transforms and distributions are in one to one correspondence, we see that $\bar{X}$ converges to $Y = \mu$ in distribution as $n$ goes to $\infty$.


\subsection{Huffman Questions}
(a) Consider the set of $2^n$ bitstrings of length $n$ each denoting a separate possibility in the state space. For example, $\P[``x_1x_2\dots x_n"] = \P[X_1 = x_1]\P[X_2 = x_2]\dots\P[X_n = x_n]$, which is known since we know $p_1$ through $p_n$. Now construct the huffman coding tree corresponding to each of these $2^n$ bitstrings and their respecitve probabilities. Each question we ask will take one branch of the tree (the branch with the higher frequency) and ask "Is the desired bitstring among one of the leaf nodes in this subtree?". In this manner, we traverse down the tree until we reach the bottom and obtain the desired bitstring representing good and defective objects. The tree has an average branching factor of 2, and there are $2^n$ leaf nodes, so the height is $O(n)$. Since the tree has depth $O(n)$, our algorithm runs in $O(n)$ number of questions asked.

(b) The longest possible sequence of questions corresponds to the the leaf nodes with the least frequency. Since $p_n$ is smaller than all the other $p_i$, $(1-p_i)$ is smaller than $(1 - p_n)$ for all the $i < n$, and so the node we want is the question that asks "Is the value of $X_n$ 1 (or 0)?". We are distinguishing between element "00...00" and "00...01", that is, between element whose last value is 0 and whose last value is 1, essentially determining the value of last bit $X_n$.

\subsection{Number of Parameters}
(a) Since we have $n$ arbitrary binary random variables, we have a state space of size $2^{n + 1}$. However, if we know $2^{n + 1} - 1$ of the probabilities, we know the last one, since they must all sum to 1. Thus we need $2^{n + 1} - 1$ parameters needed to characterize the joint distribution.

(b) Since the random variables are independent, we have $\P[Z_0 = z_0, \dots, Z_n = z_n] = \P[Z_0 = z_0]\dots\P[Z_n = z_n]$, so we only need to know 1 value for each $Z_i$, namely $\P[Z_i = 0]$ (from which we get $\P[Z_i = 1]$). Thus we need $(n + 1)$ parameters to characterize the joint distribution.

(c) Since markov chains have the amnesia property, we can break up the distribution as
\[
    \P[X_0 = x_0, \dots, X_n = x_n] = \P[X_n = x_n | X_{n - 1} = x_{n - 1}]\dots\P[X_1 = x_1 | X_0 = x_0]\P[X_0 = x_0].
\]
It follows then that all we need to know are the transition probabilities, and there are four of these, as well as the initial state probabilities, two of these. More precisely, we need to know the four values of
\[P = \left[\begin{tabular}{cc}
    $p_{00}$ & $p_{01}$ \\
    $p_{10}$ & $p_{11}$
\end{tabular}\right]\]
and the two values
\[
\P[X_0 = 0] \quad \P[X_0 = 1],
\]
from which we can calculate $\P[X_0 = x_0, \dots, X_n = x_n]$ using the amnesia property above. Thus 3 parameters are needed to characterize the joint distribution, the initial state distribution $\pi_0$ (for which we only need to know the probability of one state, as it gives us the other) and $p_{00}$ and $p_{10}$ (since $p_{00}$ gives us $p_{01}$ and $p_{10}$ gives us $p_{11}$).

(d) Markov chains must satisfy the Markov Property (or amensia property). In other words,
\[
    \P[X_{n + 1} = j | X_n = i, \dots, X_0 = x_0] = \P[X_{n + 1} = j | X_n = i] = p_{ij},
\]
and we must have
\[
    \sum_j p_{ij} = 1.
\]
However, since this sequence of random variables $Z_0, Z_1, \dots, Z_n, \dots$ are independent, we have that
\[
   \forall j \quad p_{ij} = \P[X_{n + 1} = j].
\]
But then our transition probabilities $p_{ij}$ are not necessarily well defined. For example, let $Z_i$ be defined on the state space $\{0, 1\}$, where $\P[Z_i = 1] = \frac{1}{i + 1}$ for odd $i$ and $\P[Z_i = 1] = 1 - \frac{1}{i + 1}$ for even $i$. Then $p_{01} = \P[Z_2 = 1 | Z_1 = 0] = \P[Z_2 = 1] = 2/3$, but we also have $p_{01} = \P[Z_1 = 1|Z_0 = 0] = \P[Z_1 = 1] = 1/2 \neq 2/3$. Note that for odd indices, the chain converges to 0 whereas for even indices it converges to 1, so the markov chain as a whole does not converge to some stationary distribution, and is hence not time invariant. In essence, markov chains model random variables where consecutive random variables are dependent, whereas with this sequence, the $Z_i$ are independent and can be defined in a way to violate the markov property.


\subsection{Backwards Markov Property}
Keeping in mind the markov property and using Bayes rule, we have
\begin{align*}
    &\P[X_k = i_0 | X_{k + 1} = i_1, \dots, X_{k + m} = i_{m}] \\
    &= \frac{\P[X_k = i_0, \dots, X_{k + m} = i_m]}{\P[X_{k + 1} = i_1, \dots, X_{k + m} = i_m]} \\
    &= \frac{\P[X_{k + m} = i_m, \dots, X_{k + 2} = i_2 | X_{k + 1} = i_1]\P[X_{k + 1} = i_1 | X_k = i_0]\P[X_k = i_0]}{\P[X_{k + m} = i_m, \dots, X_{k + 2} = i_2 | X_{k + 1} = i_1]\P[X_{k + 1} = i_1]} \\
    &= \frac{\P[X_{k + 1} = i_1 | X_k = i_0]\P[X_k = i_0]}{\P[X_{k + 1} = i_1]} \\
    &= \P[X_k = i_0 | X_{k + 1} = i_1],
\end{align*}
hence proving the backwards markov property.
